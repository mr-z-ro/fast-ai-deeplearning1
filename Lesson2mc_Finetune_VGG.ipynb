{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning VGG's Last Layer\n",
    "\n",
    "In this exercise, we'll fine tune the final layer of VGG (since it's already a linear layer using softmax activation!) as opposed to adding one outside the model.\n",
    "\n",
    "## Update Model Architecture\n",
    "\n",
    "We'll start by importing the VGG model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg16 import Vgg16\n",
    "vgg = Vgg16()\n",
    "model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_8 (Lambda)            (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_92 (ZeroPaddi (None, 3, 226, 226)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_93 (ZeroPaddi (None, 64, 226, 226)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_94 (ZeroPaddi (None, 64, 114, 114)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_95 (ZeroPaddi (None, 128, 114, 114)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_96 (ZeroPaddi (None, 128, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_97 (ZeroPaddi (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_98 (ZeroPaddi (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_99 (ZeroPaddi (None, 256, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_100 (ZeroPadd (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_101 (ZeroPadd (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_102 (ZeroPadd (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_103 (ZeroPadd (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_104 (ZeroPadd (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, yep the last layer is a dense layer. Let's pop it off and replace it with our own, and lock all previous layers' so that we can only train the last layer while maintaining the benefits of layers trained on ImageNet features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.pop()\n",
    "for layer in model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_8 (Lambda)            (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_92 (ZeroPaddi (None, 3, 226, 226)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_93 (ZeroPaddi (None, 64, 226, 226)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_94 (ZeroPaddi (None, 64, 114, 114)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_95 (ZeroPaddi (None, 128, 114, 114)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_96 (ZeroPaddi (None, 128, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_97 (ZeroPaddi (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_98 (ZeroPaddi (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_99 (ZeroPaddi (None, 256, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_100 (ZeroPadd (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_101 (ZeroPadd (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_102 (ZeroPadd (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_103 (ZeroPadd (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_104 (ZeroPadd (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's train it\n",
    "\n",
    "First, load data in from lesson 2b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "from utils import get_data\n",
    "\n",
    "path = '../../../data/dogscats/'\n",
    "model_path = path + 'models/'\n",
    "\n",
    "#trn_data = get_data(path+'train')\n",
    "#val_data = get_data(path+'valid')\n",
    "#val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3, 224, 224)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]\n",
    "\n",
    "#save_array(model_path+'train_data.bc', trn_data)\n",
    "#save_array(model_path+'valid_data.bc', val_data)\n",
    "trn_data = load_array(model_path+'train_data.bc')\n",
    "val_data = load_array(model_path+'valid_data.bc')\n",
    "val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and one-hot-encoded labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 23000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import get_batches\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def onehot(x): return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())\n",
    "\n",
    "# Load up the labels\n",
    "# Use batch size of 1 since we're just doing preprocessing on the CPU\n",
    "val_batches = get_batches(path+'valid', shuffle=False, batch_size=1)\n",
    "batches = get_batches(path+'train', shuffle=False, batch_size=1)\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)\n",
    "\n",
    "# Load the batches for actual training\n",
    "from keras.preprocessing import image\n",
    "gen=image.ImageDataGenerator()\n",
    "batches = gen.flow(trn_data, trn_labels, batch_size=batch_size, shuffle=True)\n",
    "val_batches = gen.flow(val_data, val_labels, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(optimizer=opt, \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and Train! (creating a function to make retraining easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_batch_size = 250\n",
    "def fit_model(model, batches, val_batches, epochs=1):\n",
    "    model.fit_generator(batches, \n",
    "                        steps_per_epoch=batches.n/fit_batch_size, \n",
    "                        epochs=epochs, \n",
    "                        validation_data=val_batches, \n",
    "                        validation_steps=val_batches.n/fit_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "92/92 [==============================] - 39s - loss: 0.1539 - acc: 0.9517 - val_loss: 0.0291 - val_acc: 0.9900\n",
      "Epoch 2/4\n",
      "92/92 [==============================] - 39s - loss: 0.1010 - acc: 0.9730 - val_loss: 0.0386 - val_acc: 0.9863\n",
      "Epoch 3/4\n",
      "92/92 [==============================] - 39s - loss: 0.1025 - acc: 0.9745 - val_loss: 0.0898 - val_acc: 0.9738\n",
      "Epoch 4/4\n",
      "92/92 [==============================] - 39s - loss: 0.0899 - acc: 0.9796 - val_loss: 0.0466 - val_acc: 0.9900\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, batches, val_batches, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model (Weights) Out to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(model_path + 'finetune1.h5')\n",
    "#model.load_weights(model_path + 'finetune1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 8s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.051719786184896296, 0.98399999999999999]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 7s     \n",
      "2000/2000 [==============================] - 7s     \n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_classes(val_data, batch_size=100)\n",
    "probs = model.predict_proba(val_data, batch_size=100)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[987  13]\n",
      " [ 19 981]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAEmCAYAAAAN9HleAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCwjB6eZWUb/H/8W7JK/JvQ6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c96e5c518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import plot_confusion_matrix\n",
    "cm = confusion_matrix(val_classes, preds)\n",
    "plot_confusion_matrix(cm, {'cat':0, 'dog':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load up the labels\n",
    "# Use batch size of 1 since we're just doing preprocessing on the CPU\n",
    "tst_batches = get_batches(path+'test-redux', shuffle=False, batch_size=1)\n",
    "tst_classes = tst_batches.classes\n",
    "tst_labels = onehot(tst_classes)\n",
    "\n",
    "# Load the data\n",
    "tst_data = get_data(path+'test-redux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 49s    \n"
     ]
    }
   ],
   "source": [
    "tst_probs = model.predict_proba(tst_data, batch_size=100)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dog = np.array(1-tst_probs)\n",
    "prob_dog = prob_dog.clip(min=0.02, max=0.98)\n",
    "\n",
    "idx = [int(fn.split('/')[1].split('.')[0]) for fn in tst_batches.filenames]\n",
    "\n",
    "prob_dog_idx = np.c_[np.array(idx), prob_dog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.4960e+03,   2.0000e-02],\n",
       "       [  1.0203e+04,   9.8000e-01],\n",
       "       [  1.9230e+03,   2.0000e-02],\n",
       "       [  2.0560e+03,   9.8000e-01],\n",
       "       [  8.5060e+03,   2.0000e-02]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dog_idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(path+\"test-redux-preds.csv\", prob_dog_idx,\"%d,%f\",header=\"id,label\", comments=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 250 people on Kaggle! (225th to be precise!)\n",
    "\n",
    "Next up, training more layers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
